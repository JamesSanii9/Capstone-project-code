{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from random import seed\nfrom random import random\nimport numpy as np\n# seed random number generator\nseed(1)\n\nimport cv2\nimport os\nfiles = os.listdir(\"../input/capstone-good-dataset/Dataset\")\ni = 0\nj=0\nimages = []\nwhile i < 11000:\n    if i < 10:\n        temp = \"000\"+str(i)\n    elif i >= 10 and i < 100:\n        temp = \"00\"+str(i)\n    elif i >= 100 and i<1000:\n        temp = \"0\"+str(i)\n    else:\n        temp = str(i)\n    i = i+1\n    if i>6000:\n        if j<4000 and (random()<0.9):\n            images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n            j += 1\n    else:    \n        images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n\ny = []\nj = 0\nwhile j < 11000:\n    if j <= 1999:\n        y.append(\"in bed\")\n    elif j >= 2000 and j <=3999:\n        y.append(\"getting out of bed\")\n    elif j >= 4000 and j <=5999:\n        y.append(\"out of bed\")\n    elif j >= 6000 and j <=9999:\n        y.append(\"injured\")\n    j += 1\n    \ny = np.array(y)\nx_data = np.array(images).reshape(10000, 224, 224, 3)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\nprint(onehot_encoded)\nX_train, X_test, y_train, y_test = train_test_split(x_data, onehot_encoded, test_size=0.2, random_state=42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-07T20:59:07.411777Z","iopub.execute_input":"2022-04-07T20:59:07.412154Z","iopub.status.idle":"2022-04-07T21:02:17.608317Z","shell.execute_reply.started":"2022-04-07T20:59:07.412051Z","shell.execute_reply":"2022-04-07T21:02:17.607552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run this part if using images with one person, one camera angle\n\n# seed random number generator\nseed(1)\n\nimport cv2\nimport os\nfiles = os.listdir(\"../input/capstone-good-dataset/Dataset\")\ni = 0\nj=0\nimages = []\nwhile i < 11000:\n    if i < 10:\n        temp = \"000\"+str(i)\n    elif i >= 10 and i < 100:\n        temp = \"00\"+str(i)\n    elif i >= 100 and i<1000:\n        temp = \"0\"+str(i)\n    else:\n        temp = str(i)\n    i = i+1\n    if i>6000:\n        if j<4000 and (random()<0.9):\n            images.append((cv2.resize(cv2.imread(\"../input/capstone-experiments/DatasetFixedCamSinglePatient/DatasetFixedCamSinglePatient/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n            j += 1\n    else:    \n        images.append((cv2.resize(cv2.imread(\"../input/capstone-experiments/DatasetFixedCamSinglePatient/DatasetFixedCamSinglePatient/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n\ny = []\nj = 0\nwhile j < 11000:\n    if j <= 1999:\n        y.append(\"in bed\")\n    elif j >= 2000 and j <=3999:\n        y.append(\"getting out of bed\")\n    elif j >= 4000 and j <=5999:\n        y.append(\"out of bed\")\n    elif j >= 6000 and j <=9999:\n        y.append(\"injured\")\n    j += 1\n    \ny = np.array(y)\nx_data = np.array(images).reshape(10000, 224, 224, 3)\n\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\nprint(onehot_encoded)\nX_train, X_test_dont_use, y_train, y_test_dont_use = train_test_split(x_data, onehot_encoded, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T22:42:10.180952Z","iopub.execute_input":"2022-04-06T22:42:10.181974Z","iopub.status.idle":"2022-04-06T22:45:48.647063Z","shell.execute_reply.started":"2022-04-06T22:42:10.181887Z","shell.execute_reply":"2022-04-06T22:45:48.646022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run this part if using images with one person, multiple camera angles\n\n# seed random number generator\nseed(1)\n\nimport cv2\nimport os\nfiles = os.listdir(\"../input/capstone-good-dataset/Dataset\")\ni = 0\nj=0\nimages = []\nwhile i < 11000:\n    if i < 10:\n        temp = \"000\"+str(i)\n    elif i >= 10 and i < 100:\n        temp = \"00\"+str(i)\n    elif i >= 100 and i<1000:\n        temp = \"0\"+str(i)\n    else:\n        temp = str(i)\n    i = i+1\n    if i>6000:\n        if j<4000 and (random()<0.9):\n            images.append((cv2.resize(cv2.imread(\"../input/capstone-experiments/DatasetSinglePatient/DatasetSinglePatient/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n            j += 1\n    else:    \n        images.append((cv2.resize(cv2.imread(\"../input/capstone-experiments/DatasetSinglePatient/DatasetSinglePatient/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n\ny = []\nj = 0\nwhile j < 11000:\n    if j <= 1999:\n        y.append(\"in bed\")\n    elif j >= 2000 and j <=3999:\n        y.append(\"getting out of bed\")\n    elif j >= 4000 and j <=5999:\n        y.append(\"out of bed\")\n    elif j >= 6000 and j <=9999:\n        y.append(\"injured\")\n    j += 1\n    \ny = np.array(y)\nx_data = np.array(images).reshape(10000, 224, 224, 3)\n\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\nprint(onehot_encoded)\nX_train, X_test_dont_use, y_train, y_test_dont_use = train_test_split(x_data, onehot_encoded, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T23:14:04.833065Z","iopub.execute_input":"2022-04-06T23:14:04.833344Z","iopub.status.idle":"2022-04-06T23:17:11.026522Z","shell.execute_reply.started":"2022-04-06T23:14:04.833306Z","shell.execute_reply":"2022-04-06T23:17:11.025796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run this part if using images with multiple people, 1 camera angle\n\n# seed random number generator\nseed(1)\n\nimport cv2\nimport os\n\nfiles = os.listdir(\"../input/capstone-good-dataset/Dataset\")\ni = 0\nj=0\nimages = []\nwhile i < 11000:\n    if i < 10:\n        temp = \"000\"+str(i)\n    elif i >= 10 and i < 100:\n        temp = \"00\"+str(i)\n    elif i >= 100 and i<1000:\n        temp = \"0\"+str(i)\n    else:\n        temp = str(i)\n    i = i+1\n    if i>6000:\n        if j<4000 and (random()<0.9):\n            images.append((cv2.resize(cv2.imread(\"../input/capstone-experiments/DatasetSinglePatient/DatasetSinglePatient/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n            j += 1\n    else:    \n        images.append((cv2.resize(cv2.imread(\"../input/capstone-experiments/DatasetSinglePatient/DatasetSinglePatient/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n\ny = []\nj = 0\nwhile j < 11000:\n    if j <= 1999:\n        y.append(\"in bed\")\n    elif j >= 2000 and j <=3999:\n        y.append(\"getting out of bed\")\n    elif j >= 4000 and j <=5999:\n        y.append(\"out of bed\")\n    elif j >= 6000 and j <=9999:\n        y.append(\"injured\")\n    j += 1\n    \ny = np.array(y)\nx_data = np.array(images).reshape(10000, 224, 224, 3)\n\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\nprint(onehot_encoded)\nX_train, X_test_dont_use, y_train, y_test_dont_use = train_test_split(x_data, onehot_encoded, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T23:51:41.646978Z","iopub.execute_input":"2022-04-06T23:51:41.647268Z","iopub.status.idle":"2022-04-06T23:53:53.283906Z","shell.execute_reply.started":"2022-04-06T23:51:41.647236Z","shell.execute_reply":"2022-04-06T23:53:53.282903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run for VGG16 test\n\nimport gc\n#del integer_encoded,onehot_encoded\n#del images, X_test_dont_use\n#gc.collect()\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\nimport os\nimport time\n\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\nbase_model = VGG16(input_shape = (320, 180, 3),include_top = False, weights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(512, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = layers.Dropout(0.5)(x)\n\nx = layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n#ask if shear or rotation range makes any sense\n#no vertical flip since it does not makes sense\n#rescale used to normalize image between 0 and 1\n\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    width_shift_range=0.05, #shifts image left/right\n    height_shift_range=0.05, #shift image up/down\n    horizontal_flip=True, \n    brightness_range = (0.8, 1), #changes brightness, can use this to simulate different lighting intensities\n    zoom_range = [0.9,1.0], #zoom in on image, no zoom out applied\n    #rescale=1.0/255.0, #normalizes the pixels\n    validation_split=0.2)\n\ntraining_generator = datagen.flow(X_train, y_train, batch_size=64,subset='training',seed=7)\nvalidation_generator = datagen.flow(X_train, y_train, batch_size=64,subset='validation',seed=7)\n\nloss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=50)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:03:34.000533Z","iopub.execute_input":"2022-04-07T14:03:34.001096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\nimport gc\n#del integer_encoded,onehot_encoded\ndel images\ngc.collect()\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\nimport os\nimport time\n\nbase_model = ResNet50(input_shape = (320, 180, 3),include_top = False, weights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)\n\nx = layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0003), loss = tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    width_shift_range=0.05, #shifts image left/right\n    height_shift_range=0.05, #shift image up/down\n    horizontal_flip=True, \n    brightness_range = (0.8, 1), #changes brightness, can use this to simulate different lighting intensities\n    zoom_range = [0.9,1.0], #zoom in on image, no zoom out applied\n    #rescale=1.0/255.0, #normalizes the pixels\n    validation_split=0.2)\n\ntraining_generator = datagen.flow(X_train, y_train, batch_size=64,subset='training',seed=7)\nvalidation_generator = datagen.flow(X_train, y_train, batch_size=64,subset='validation',seed=7)\n\nloss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=35)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n        \nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:18:28.839392Z","iopub.execute_input":"2022-04-07T19:18:28.839702Z","iopub.status.idle":"2022-04-07T20:27:57.759451Z","shell.execute_reply.started":"2022-04-07T19:18:28.839667Z","shell.execute_reply":"2022-04-07T20:27:57.758797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=35)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n        \nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T20:28:42.871609Z","iopub.execute_input":"2022-04-07T20:28:42.871863Z","iopub.status.idle":"2022-04-07T20:55:43.013663Z","shell.execute_reply.started":"2022-04-07T20:28:42.871833Z","shell.execute_reply":"2022-04-07T20:55:43.008148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\nbase_model = InceptionV3(input_shape = (320, 180, 3),include_top = False, weights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = layers.Dropout(0.5)(x)\n\nx = layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.000005), loss = tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    width_shift_range=0.05, #shifts image left/right\n    height_shift_range=0.05, #shift image up/down\n    horizontal_flip=True, \n    brightness_range = (0.8, 1), #changes brightness, can use this to simulate different lighting intensities\n    zoom_range = [0.9,1.0], #zoom in on image, no zoom out applied\n    rescale=1.0/255.0, #normalizes the pixels\n    validation_split=0.2)\n\ntraining_generator = datagen.flow(X_train, y_train, batch_size=64,subset='training',seed=7)\nvalidation_generator = datagen.flow(X_train, y_train, batch_size=64,subset='validation',seed=7)\n\nloss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=35)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\nprint(prediction)\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n        \nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:22:56.939205Z","iopub.execute_input":"2022-04-07T15:22:56.939555Z","iopub.status.idle":"2022-04-07T16:29:30.78172Z","shell.execute_reply.started":"2022-04-07T15:22:56.939511Z","shell.execute_reply":"2022-04-07T16:29:30.779775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=35)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\nprint(prediction)\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n        \nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T16:29:30.785599Z","iopub.execute_input":"2022-04-07T16:29:30.786075Z","iopub.status.idle":"2022-04-07T17:36:51.140796Z","shell.execute_reply.started":"2022-04-07T16:29:30.786028Z","shell.execute_reply":"2022-04-07T17:36:51.139755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\nimport gc\n#del integer_encoded,onehot_encoded\n\n\n\nfrom tensorflow.keras.applications import EfficientNetB0\nbase_model = EfficientNetB0(weights='imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = layers.Dropout(0.2)(x)\n\nx = layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.05), loss = tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    width_shift_range=0.05, #shifts image left/right\n    height_shift_range=0.05, #shift image up/down\n    horizontal_flip=True, \n    brightness_range = (0.8, 1), #changes brightness, can use this to simulate different lighting intensities\n    zoom_range = [0.9,1.0], #zoom in on image, no zoom out applied\n    #rescale=1.0/255.0, #normalizes the pixels\n    validation_split=0.2)\n\ntraining_generator = datagen.flow(X_train, y_train, batch_size=64,subset='training',seed=7)\nvalidation_generator = datagen.flow(X_train, y_train, batch_size=64,subset='validation',seed=7)\n\nloss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=100)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\n\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n        \nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T21:02:17.609981Z","iopub.execute_input":"2022-04-07T21:02:17.610537Z","iopub.status.idle":"2022-04-07T23:40:20.931518Z","shell.execute_reply.started":"2022-04-07T21:02:17.610497Z","shell.execute_reply":"2022-04-07T23:40:20.930783Z"},"trusted":true},"execution_count":null,"outputs":[]}]}