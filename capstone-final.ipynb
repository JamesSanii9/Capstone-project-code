{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-10T14:38:14.702757Z","iopub.execute_input":"2022-03-10T14:38:14.705089Z","iopub.status.idle":"2022-03-10T14:38:14.744594Z","shell.execute_reply.started":"2022-03-10T14:38:14.704942Z","shell.execute_reply":"2022-03-10T14:38:14.741276Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from random import seed\nfrom random import random\n# seed random number generator\nseed(1)\n\nimport cv2\nimport os\nfiles = os.listdir(\"../input/capstone-good-dataset/Dataset\")\ni = 0\nj=0\nimages = []\nwhile i < 11000:\n    if i < 10:\n        temp = \"000\"+str(i)\n    elif i >= 10 and i < 100:\n        temp = \"00\"+str(i)\n    elif i >= 100 and i<1000:\n        temp = \"0\"+str(i)\n    else:\n        temp = str(i)\n    i = i+1\n    if i>6000:\n        if j<4000 and (random()<0.9):\n            images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(320, 180), interpolation=cv2.INTER_CUBIC)))\n            j += 1\n    else:    \n        images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(320, 180), interpolation=cv2.INTER_CUBIC)))\n\ny = []\nj = 0\nwhile j < 11000:\n    if j <= 1999:\n        y.append(\"in bed\")\n    elif j >= 2000 and j <=3999:\n        y.append(\"getting out of bed\")\n    elif j >= 4000 and j <=5999:\n        y.append(\"out of bed\")\n    elif j >= 6000 and j <=9999:\n        y.append(\"injured\")\n    j += 1\n    \ny = np.array(y)\nx_data = np.array(images).reshape(10000, 320, 180, 3)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T14:38:14.746352Z","iopub.execute_input":"2022-03-10T14:38:14.746753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T14:41:13.286171Z","iopub.execute_input":"2022-03-09T14:41:13.286513Z","iopub.status.idle":"2022-03-09T14:41:13.652528Z","shell.execute_reply.started":"2022-03-09T14:41:13.286462Z","shell.execute_reply":"2022-03-09T14:41:13.651724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\nimport os\nimport time\n\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\nbase_model = VGG16(input_shape = (320, 180, 3),include_top = False, weights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(512, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = layers.Dropout(0.5)(x)\n\nx = layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\nprint(onehot_encoded)\nX_train, X_test, y_train, y_test = train_test_split(x_data, onehot_encoded, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T15:31:42.731935Z","iopub.execute_input":"2022-03-09T15:31:42.732387Z","iopub.status.idle":"2022-03-09T15:31:43.857203Z","shell.execute_reply.started":"2022-03-09T15:31:42.732345Z","shell.execute_reply":"2022-03-09T15:31:43.856401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.shape(y_train))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T15:22:00.624576Z","iopub.execute_input":"2022-03-09T15:22:00.624828Z","iopub.status.idle":"2022-03-09T15:22:00.629679Z","shell.execute_reply.started":"2022-03-09T15:22:00.6248Z","shell.execute_reply":"2022-03-09T15:22:00.628848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ask if shear or rotation range makes any sense\n#no vertical flip since it does not makes sense\n#rescale used to normalize image between 0 and 1\n\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    #width_shift_range=0.05, #shifts image left/right\n    #height_shift_range=0.05, #shift image up/down\n    #horizontal_flip=True, \n    #brightness_range = (0.8, 1), #changes brightness, can use this to simulate different lighting intensities\n    #zoom_range = [0.9,1.0], #zoom in on image, no zoom out applied\n    #rescale=1.0/255.0, #normalizes the pixels\n    validation_split=0.2)\n\ntraining_generator = datagen.flow(X_train, y_train, batch_size=64,subset='training',seed=7)\nvalidation_generator = datagen.flow(X_train, y_train, batch_size=64,subset='validation',seed=7)\n\nloss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T15:31:43.859415Z","iopub.execute_input":"2022-03-09T15:31:43.859784Z","iopub.status.idle":"2022-03-09T15:37:21.741724Z","shell.execute_reply.started":"2022-03-09T15:31:43.859743Z","shell.execute_reply":"2022-03-09T15:37:21.740994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T15:37:21.743549Z","iopub.execute_input":"2022-03-09T15:37:21.743822Z","iopub.status.idle":"2022-03-09T15:37:30.11209Z","shell.execute_reply.started":"2022-03-09T15:37:21.743786Z","shell.execute_reply":"2022-03-09T15:37:30.111232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_test)\nprint(y_pred_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T15:37:30.113526Z","iopub.execute_input":"2022-03-09T15:37:30.115491Z","iopub.status.idle":"2022-03-09T15:37:30.121737Z","shell.execute_reply.started":"2022-03-09T15:37:30.115456Z","shell.execute_reply":"2022-03-09T15:37:30.12103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\nprint(prediction)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T15:37:30.12321Z","iopub.execute_input":"2022-03-09T15:37:30.12424Z","iopub.status.idle":"2022-03-09T15:37:30.16551Z","shell.execute_reply.started":"2022-03-09T15:37:30.124198Z","shell.execute_reply":"2022-03-09T15:37:30.164811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T15:37:30.166921Z","iopub.execute_input":"2022-03-09T15:37:30.167428Z","iopub.status.idle":"2022-03-09T15:37:30.236622Z","shell.execute_reply.started":"2022-03-09T15:37:30.167391Z","shell.execute_reply":"2022-03-09T15:37:30.235796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T15:37:30.238094Z","iopub.execute_input":"2022-03-09T15:37:30.238351Z","iopub.status.idle":"2022-03-09T15:37:30.251318Z","shell.execute_reply.started":"2022-03-09T15:37:30.238316Z","shell.execute_reply":"2022-03-09T15:37:30.250389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T15:37:30.253703Z","iopub.execute_input":"2022-03-09T15:37:30.254226Z","iopub.status.idle":"2022-03-09T15:37:30.270255Z","shell.execute_reply.started":"2022-03-09T15:37:30.254189Z","shell.execute_reply":"2022-03-09T15:37:30.269577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\nfrom random import seed\nfrom random import random\n# seed random number generator\nseed(1)\nimport numpy as np\nimport cv2\nimport os\nfiles = os.listdir(\"../input/capstone-good-dataset/Dataset\")\ni = 0\nj=0\nimages = []\nwhile i < 11000:\n    if i < 10:\n        temp = \"000\"+str(i)\n    elif i >= 10 and i < 100:\n        temp = \"00\"+str(i)\n    elif i >= 100 and i<1000:\n        temp = \"0\"+str(i)\n    else:\n        temp = str(i)\n    i = i+1\n    if i>6000:\n        if j<4000 and (random()<0.9):\n            images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(320, 180), interpolation=cv2.INTER_CUBIC)))\n            j += 1\n    else:    \n        images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(320, 180), interpolation=cv2.INTER_CUBIC)))\n\ny = []\nj = 0\nwhile j < 11000:\n    if j <= 1999:\n        y.append(\"in bed\")\n    elif j >= 2000 and j <=3999:\n        y.append(\"getting out of bed\")\n    elif j >= 4000 and j <=5999:\n        y.append(\"out of bed\")\n    elif j >= 6000 and j <=9999:\n        y.append(\"injured\")\n    j += 1\n    \ny = np.array(y)\nx_data = np.array(images).reshape(10000, 320, 180, 3)\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\nprint(onehot_encoded)\nX_train, X_test, y_train, y_test = train_test_split(x_data, onehot_encoded, test_size=0.2, random_state=42)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T00:25:29.625196Z","iopub.execute_input":"2022-03-10T00:25:29.625483Z","iopub.status.idle":"2022-03-10T00:27:26.953168Z","shell.execute_reply.started":"2022-03-10T00:25:29.625445Z","shell.execute_reply":"2022-03-10T00:27:26.952451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = InceptionV3(input_shape = (320, 180, 3),include_top = False, weights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = layers.Dropout(0.5)(x)\n\nx = layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.000005), loss = tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    #width_shift_range=0.05, #shifts image left/right\n    #height_shift_range=0.05, #shift image up/down\n    #horizontal_flip=True, \n    #brightness_range = (0.8, 1), #changes brightness, can use this to simulate different lighting intensities\n    #zoom_range = [0.9,1.0], #zoom in on image, no zoom out applied\n    #rescale=1.0/255.0, #normalizes the pixels\n    validation_split=0.2)\n\ntraining_generator = datagen.flow(X_train, y_train, batch_size=64,subset='training',seed=7)\nvalidation_generator = datagen.flow(X_train, y_train, batch_size=64,subset='validation',seed=7)\n\nloss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=150)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\nprint(prediction)\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n        \nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\nfrom random import seed\nfrom random import random\n# seed random number generator\nseed(1)\nimport numpy as np\nimport cv2\nimport os\nfiles = os.listdir(\"../input/capstone-good-dataset/Dataset\")\ni = 0\nj=0\nimages = []\nwhile i < 11000:\n    if i < 10:\n        temp = \"000\"+str(i)\n    elif i >= 10 and i < 100:\n        temp = \"00\"+str(i)\n    elif i >= 100 and i<1000:\n        temp = \"0\"+str(i)\n    else:\n        temp = str(i)\n    i = i+1\n    if i>6000:\n        if j<4000 and (random()<0.9):\n            images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(320, 180), interpolation=cv2.INTER_CUBIC)))\n            j += 1\n    else:    \n        images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(320, 180), interpolation=cv2.INTER_CUBIC)))\n\ny = []\nj = 0\nwhile j < 11000:\n    if j <= 1999:\n        y.append(\"in bed\")\n    elif j >= 2000 and j <=3999:\n        y.append(\"getting out of bed\")\n    elif j >= 4000 and j <=5999:\n        y.append(\"out of bed\")\n    elif j >= 6000 and j <=9999:\n        y.append(\"injured\")\n    j += 1\n    \ny = np.array(y)\nx_data = np.array(images).reshape(10000, 320, 180, 3)\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\nX_train, X_test, y_train, y_test = train_test_split(x_data, onehot_encoded, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T18:03:16.390083Z","iopub.execute_input":"2022-03-10T18:03:16.390384Z","iopub.status.idle":"2022-03-10T18:06:39.370007Z","shell.execute_reply.started":"2022-03-10T18:03:16.390308Z","shell.execute_reply":"2022-03-10T18:06:39.368871Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\n\n\nbase_model = ResNet50(input_shape = (320, 180, 3),include_top = False, weights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = layers.Dropout(0.2)(x)\n\nx = layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0002), loss = tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    #width_shift_range=0.05, #shifts image left/right\n    #height_shift_range=0.05, #shift image up/down\n    #horizontal_flip=True, \n    #brightness_range = (0.8, 1), #changes brightness, can use this to simulate different lighting intensities\n    #zoom_range = [0.9,1.0], #zoom in on image, no zoom out applied\n    #rescale=1.0/255.0, #normalizes the pixels\n    validation_split=0.2)\n\ntraining_generator = datagen.flow(X_train, y_train, batch_size=64,subset='training',seed=7)\nvalidation_generator = datagen.flow(X_train, y_train, batch_size=64,subset='validation',seed=7)\n\nloss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=35)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n        \nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T18:06:39.375077Z","iopub.execute_input":"2022-03-10T18:06:39.375354Z","iopub.status.idle":"2022-03-10T18:18:49.732874Z","shell.execute_reply.started":"2022-03-10T18:06:39.375320Z","shell.execute_reply":"2022-03-10T18:18:49.731354Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2022-03-10 18:06:39.701084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-10 18:06:39.830340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-10 18:06:39.831131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-10 18:06:39.832852: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-03-10 18:06:39.833923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-10 18:06:39.834636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-10 18:06:39.835294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-10 18:06:41.605122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-10 18:06:41.605945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-10 18:06:41.606681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-10 18:06:41.607331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 1s 0us/step\n94781440/94765736 [==============================] - 1s 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn('This ImageDataGenerator specifies '\n/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn('This ImageDataGenerator specifies '\n2022-03-10 18:06:47.544919: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/35\n","output_type":"stream"},{"name":"stderr","text":"2022-03-10 18:06:52.132881: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"100/100 [==============================] - 32s 214ms/step - loss: 10.9638 - auc: 0.6804 - categorical_accuracy: 0.4636 - val_loss: 7.6904 - val_auc: 0.6954 - val_categorical_accuracy: 0.4706\nEpoch 2/35\n100/100 [==============================] - 20s 203ms/step - loss: 1.8878 - auc: 0.8392 - categorical_accuracy: 0.6406 - val_loss: 0.4984 - val_auc: 0.9558 - val_categorical_accuracy: 0.7881\nEpoch 3/35\n100/100 [==============================] - 20s 203ms/step - loss: 0.8349 - auc: 0.9099 - categorical_accuracy: 0.7250 - val_loss: 0.8916 - val_auc: 0.9099 - val_categorical_accuracy: 0.7056\nEpoch 4/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.6347 - auc: 0.9390 - categorical_accuracy: 0.7747 - val_loss: 0.3045 - val_auc: 0.9837 - val_categorical_accuracy: 0.8906\nEpoch 5/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.4885 - auc: 0.9604 - categorical_accuracy: 0.8253 - val_loss: 0.4524 - val_auc: 0.9656 - val_categorical_accuracy: 0.7962\nEpoch 6/35\n100/100 [==============================] - 20s 199ms/step - loss: 0.3775 - auc: 0.9739 - categorical_accuracy: 0.8558 - val_loss: 1.1789 - val_auc: 0.8972 - val_categorical_accuracy: 0.7475\nEpoch 7/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.3266 - auc: 0.9804 - categorical_accuracy: 0.8797 - val_loss: 0.2365 - val_auc: 0.9889 - val_categorical_accuracy: 0.9031\nEpoch 8/35\n100/100 [==============================] - 20s 201ms/step - loss: 0.2762 - auc: 0.9853 - categorical_accuracy: 0.8919 - val_loss: 0.2384 - val_auc: 0.9890 - val_categorical_accuracy: 0.9094\nEpoch 9/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.2537 - auc: 0.9869 - categorical_accuracy: 0.9130 - val_loss: 0.4013 - val_auc: 0.9722 - val_categorical_accuracy: 0.8475\nEpoch 10/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.2310 - auc: 0.9890 - categorical_accuracy: 0.9178 - val_loss: 0.1577 - val_auc: 0.9948 - val_categorical_accuracy: 0.9431\nEpoch 11/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.1693 - auc: 0.9935 - categorical_accuracy: 0.9420 - val_loss: 0.1697 - val_auc: 0.9934 - val_categorical_accuracy: 0.9400\nEpoch 12/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.1897 - auc: 0.9917 - categorical_accuracy: 0.9361 - val_loss: 0.1766 - val_auc: 0.9933 - val_categorical_accuracy: 0.9287\nEpoch 13/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.1501 - auc: 0.9948 - categorical_accuracy: 0.9438 - val_loss: 0.1759 - val_auc: 0.9934 - val_categorical_accuracy: 0.9381\nEpoch 14/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.1269 - auc: 0.9955 - categorical_accuracy: 0.9570 - val_loss: 0.1843 - val_auc: 0.9934 - val_categorical_accuracy: 0.9306\nEpoch 15/35\n100/100 [==============================] - 20s 201ms/step - loss: 0.1260 - auc: 0.9954 - categorical_accuracy: 0.9588 - val_loss: 0.1608 - val_auc: 0.9941 - val_categorical_accuracy: 0.9369\nEpoch 16/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.1183 - auc: 0.9965 - categorical_accuracy: 0.9600 - val_loss: 0.1562 - val_auc: 0.9950 - val_categorical_accuracy: 0.9431\nEpoch 17/35\n100/100 [==============================] - 20s 199ms/step - loss: 0.1077 - auc: 0.9964 - categorical_accuracy: 0.9644 - val_loss: 0.1608 - val_auc: 0.9948 - val_categorical_accuracy: 0.9394\nEpoch 18/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.0874 - auc: 0.9972 - categorical_accuracy: 0.9727 - val_loss: 0.1916 - val_auc: 0.9916 - val_categorical_accuracy: 0.9344\nEpoch 19/35\n100/100 [==============================] - 20s 201ms/step - loss: 0.1181 - auc: 0.9954 - categorical_accuracy: 0.9683 - val_loss: 0.4299 - val_auc: 0.9750 - val_categorical_accuracy: 0.8750\nEpoch 20/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.0767 - auc: 0.9981 - categorical_accuracy: 0.9748 - val_loss: 0.2614 - val_auc: 0.9864 - val_categorical_accuracy: 0.9262\nEpoch 21/35\n100/100 [==============================] - 20s 201ms/step - loss: 0.0760 - auc: 0.9980 - categorical_accuracy: 0.9758 - val_loss: 0.1452 - val_auc: 0.9956 - val_categorical_accuracy: 0.9469\nEpoch 22/35\n100/100 [==============================] - 20s 198ms/step - loss: 0.0858 - auc: 0.9958 - categorical_accuracy: 0.9780 - val_loss: 0.2711 - val_auc: 0.9867 - val_categorical_accuracy: 0.9206\nEpoch 23/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.0909 - auc: 0.9963 - categorical_accuracy: 0.9698 - val_loss: 0.1399 - val_auc: 0.9948 - val_categorical_accuracy: 0.9550\nEpoch 24/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.0777 - auc: 0.9968 - categorical_accuracy: 0.9800 - val_loss: 0.1321 - val_auc: 0.9957 - val_categorical_accuracy: 0.9525\nEpoch 25/35\n100/100 [==============================] - 20s 199ms/step - loss: 0.0651 - auc: 0.9980 - categorical_accuracy: 0.9800 - val_loss: 0.1525 - val_auc: 0.9942 - val_categorical_accuracy: 0.9419\nEpoch 26/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.0662 - auc: 0.9975 - categorical_accuracy: 0.9816 - val_loss: 0.6416 - val_auc: 0.9563 - val_categorical_accuracy: 0.8263\nEpoch 27/35\n100/100 [==============================] - 20s 203ms/step - loss: 0.0506 - auc: 0.9986 - categorical_accuracy: 0.9845 - val_loss: 0.1890 - val_auc: 0.9918 - val_categorical_accuracy: 0.9369\nEpoch 28/35\n100/100 [==============================] - 20s 199ms/step - loss: 0.0686 - auc: 0.9976 - categorical_accuracy: 0.9800 - val_loss: 0.1741 - val_auc: 0.9925 - val_categorical_accuracy: 0.9456\nEpoch 29/35\n100/100 [==============================] - 20s 202ms/step - loss: 0.0588 - auc: 0.9978 - categorical_accuracy: 0.9866 - val_loss: 0.1149 - val_auc: 0.9966 - val_categorical_accuracy: 0.9619\nEpoch 30/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.0512 - auc: 0.9980 - categorical_accuracy: 0.9859 - val_loss: 0.1390 - val_auc: 0.9950 - val_categorical_accuracy: 0.9588\nEpoch 31/35\n100/100 [==============================] - 20s 202ms/step - loss: 0.0626 - auc: 0.9978 - categorical_accuracy: 0.9833 - val_loss: 0.1524 - val_auc: 0.9943 - val_categorical_accuracy: 0.9531\nEpoch 32/35\n100/100 [==============================] - 20s 203ms/step - loss: 0.0540 - auc: 0.9980 - categorical_accuracy: 0.9864 - val_loss: 0.1677 - val_auc: 0.9941 - val_categorical_accuracy: 0.9506\nEpoch 33/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.0494 - auc: 0.9981 - categorical_accuracy: 0.9861 - val_loss: 0.1530 - val_auc: 0.9936 - val_categorical_accuracy: 0.9575\nEpoch 34/35\n100/100 [==============================] - 20s 200ms/step - loss: 0.0282 - auc: 0.9994 - categorical_accuracy: 0.9911 - val_loss: 0.2155 - val_auc: 0.9895 - val_categorical_accuracy: 0.9438\nEpoch 35/35\n100/100 [==============================] - 20s 199ms/step - loss: 0.0571 - auc: 0.9976 - categorical_accuracy: 0.9866 - val_loss: 0.1666 - val_auc: 0.9920 - val_categorical_accuracy: 0.9575\nModel accuracy score: 0.9530\nModel precision score: 0.9517\nModel recall score: 0.9442\nModel F1 score: 0.9473\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"array([[378,  14,   0,   1],\n       [ 32, 373,   5,   0],\n       [  0,   0, 793,   9],\n       [  6,   0,  27, 362]])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=1)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n        \nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T18:31:34.704047Z","iopub.execute_input":"2022-03-10T18:31:34.704549Z","iopub.status.idle":"2022-03-10T18:32:00.846044Z","shell.execute_reply.started":"2022-03-10T18:31:34.704511Z","shell.execute_reply":"2022-03-10T18:32:00.845320Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"100/100 [==============================] - 20s 201ms/step - loss: 0.0294 - auc: 0.9990 - categorical_accuracy: 0.9923 - val_loss: 0.1654 - val_auc: 0.9930 - val_categorical_accuracy: 0.9569\nModel accuracy score: 0.9610\nModel precision score: 0.9589\nModel recall score: 0.9535\nModel F1 score: 0.9559\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([[371,  22,   0,   0],\n       [ 14, 394,   2,   0],\n       [  0,   0, 794,   8],\n       [  9,   1,  22, 363]])"},"metadata":{}}]},{"cell_type":"code","source":"import gc\n#del integer_encoded,onehot_encoded\ndel images\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T18:30:17.881264Z","iopub.execute_input":"2022-03-10T18:30:17.881762Z","iopub.status.idle":"2022-03-10T18:30:18.115729Z","shell.execute_reply.started":"2022-03-10T18:30:17.881722Z","shell.execute_reply":"2022-03-10T18:30:18.114927Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"790"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ndel X_train\ngc.collect()\n\ntf.keras.models.save_model(\n    model, 'model_capstone', overwrite=True, include_optimizer=True, save_format=None,\n    signatures=None, options=None, save_traces=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T18:32:22.043932Z","iopub.execute_input":"2022-03-10T18:32:22.044234Z","iopub.status.idle":"2022-03-10T18:32:47.429738Z","shell.execute_reply.started":"2022-03-10T18:32:22.044203Z","shell.execute_reply":"2022-03-10T18:32:47.429001Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"2022-03-10 18:32:30.809256: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n2022-03-10 18:32:44.243501: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 503316480 exceeds 10% of free system memory.\n2022-03-10 18:32:44.358824: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 503316480 exceeds 10% of free system memory.\n/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"done\")\nimport shutil\nshutil.make_archive(capstone_model, 'zip', \"./model_capstone\")","metadata":{"execution":{"iopub.status.busy":"2022-03-10T18:35:56.963094Z","iopub.execute_input":"2022-03-10T18:35:56.963799Z","iopub.status.idle":"2022-03-10T18:35:57.635906Z","shell.execute_reply.started":"2022-03-10T18:35:56.963761Z","shell.execute_reply":"2022-03-10T18:35:57.634815Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/315972463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapstone_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./model_capstone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'capstone_model' is not defined"],"ename":"NameError","evalue":"name 'capstone_model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./model_capstone\"> Download File </a>","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T01:06:47.939706Z","iopub.execute_input":"2022-03-10T01:06:47.940216Z","iopub.status.idle":"2022-03-10T01:06:51.43836Z","shell.execute_reply.started":"2022-03-10T01:06:47.940179Z","shell.execute_reply":"2022-03-10T01:06:51.437428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-10T17:16:40.172909Z","iopub.execute_input":"2022-03-10T17:16:40.173469Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2022-03-10 17:16:48.825877: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\nfrom random import seed\nfrom random import random\n# seed random number generator\nseed(1)\nimport numpy as np\nimport cv2\nimport os\nfiles = os.listdir(\"../input/capstone-good-dataset/Dataset\")\ni = 0\nj=0\nimages = []\nwhile i < 11000:\n    if i < 10:\n        temp = \"000\"+str(i)\n    elif i >= 10 and i < 100:\n        temp = \"00\"+str(i)\n    elif i >= 100 and i<1000:\n        temp = \"0\"+str(i)\n    else:\n        temp = str(i)\n    i = i+1\n    if i>6000:\n        if j<4000 and (random()<0.9):\n            images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n            j += 1\n    else:    \n        images.append((cv2.resize(cv2.imread(\"../input/capstone-good-dataset/Dataset/image_\" + temp + \".jpg\"), dsize=(224, 224), interpolation=cv2.INTER_CUBIC)))\n\ny = []\nj = 0\nwhile j < 11000:\n    if j <= 1999:\n        y.append(\"in bed\")\n    elif j >= 2000 and j <=3999:\n        y.append(\"getting out of bed\")\n    elif j >= 4000 and j <=5999:\n        y.append(\"out of bed\")\n    elif j >= 6000 and j <=9999:\n        y.append(\"injured\")\n    j += 1\n    \ny = np.array(y)\nx_data = np.array(images).reshape(10000, 224, 224, 3)\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)\nprint(onehot_encoded)\nX_train, X_test, y_train, y_test = train_test_split(x_data, onehot_encoded, test_size=0.2, random_state=42)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T02:27:27.494574Z","iopub.execute_input":"2022-03-10T02:27:27.495051Z","iopub.status.idle":"2022-03-10T02:30:33.504092Z","shell.execute_reply.started":"2022-03-10T02:27:27.494934Z","shell.execute_reply":"2022-03-10T02:30:33.503317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers \nfrom tensorflow.keras import Model\n\n\nfrom tensorflow.keras.applications import EfficientNetB0\nbase_model = EfficientNetB0(weights='imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(base_model.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = layers.Dropout(0.2)(x)\n\nx = layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.models.Model(base_model.input, x)\n\nmodel.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.02), loss = tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()])\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    #width_shift_range=0.05, #shifts image left/right\n    #height_shift_range=0.05, #shift image up/down\n    #horizontal_flip=True, \n    #brightness_range = (0.8, 1), #changes brightness, can use this to simulate different lighting intensities\n    #zoom_range = [0.9,1.0], #zoom in on image, no zoom out applied\n    #rescale=1.0/255.0, #normalizes the pixels\n    validation_split=0.2)\n\ntraining_generator = datagen.flow(X_train, y_train, batch_size=64,subset='training',seed=7)\nvalidation_generator = datagen.flow(X_train, y_train, batch_size=64,subset='validation',seed=7)\n\nloss_history = model.fit_generator(training_generator,\n                        validation_data = validation_generator,\n                        steps_per_epoch = (len(X_train)*0.8) / 64,\n                        validation_steps=(len(X_train)*0.2)/64,\n                        epochs=150)\n\ny_pred_test = model.predict(X_test)\nprediction = []\nfor element in range(len(y_pred_test)):\n    if y_pred_test[element][0] > y_pred_test[element][1] and y_pred_test[element][0] > y_pred_test[element][2] and y_pred_test[element][0] > y_pred_test[element][3]:\n        prediction.append([1, 0, 0, 0])\n    elif y_pred_test[element][1] > y_pred_test[element][0] and y_pred_test[element][1] > y_pred_test[element][2] and y_pred_test[element][1] > y_pred_test[element][3]:\n        prediction.append([0, 1, 0, 0])\n    elif y_pred_test[element][2] > y_pred_test[element][1] and y_pred_test[element][2] > y_pred_test[element][0] and y_pred_test[element][2] > y_pred_test[element][3]:\n        prediction.append([0, 0, 1, 0])\n    else:\n        prediction.append([0, 0, 0, 1])\nprint(prediction)\n\nfrom sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score((y_test), prediction)))\nprint('Model precision score: {0:0.4f}'. format(precision_score((y_test), prediction, average = \"macro\")))\nprint('Model recall score: {0:0.4f}'. format(recall_score((y_test), prediction, average = \"macro\")))\nprint('Model F1 score: {0:0.4f}'. format(f1_score((y_test), prediction, average = \"macro\")))\n\nprediction_int = []\ntrue_int = []\nfor element in range(len(prediction)):\n    if prediction[element][0] == 1:\n        prediction_int.append(0)\n    elif prediction[element][1] == 1:\n        prediction_int.append(1)\n    elif prediction[element][2] == 1:\n        prediction_int.append(2)\n    else:\n        prediction_int.append(3)\n\nfor element in range(len(y_test)):\n    if y_test[element][0] == 1:\n        true_int.append(0)\n    elif y_test[element][1] == 1:\n        true_int.append(1)\n    elif y_test[element][2] == 1:\n        true_int.append(2)\n    else:\n        true_int.append(3)\n        \nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(true_int, prediction_int)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T02:30:33.5059Z","iopub.execute_input":"2022-03-10T02:30:33.506185Z","iopub.status.idle":"2022-03-10T03:03:58.500917Z","shell.execute_reply.started":"2022-03-10T02:30:33.506148Z","shell.execute_reply":"2022-03-10T03:03:58.500162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}